"""
URL Resolver Utility
Xá»­ lÃ½ viá»‡c resolve URL redirect Ä‘á»ƒ láº¥y URL cuá»‘i cÃ¹ng tá»« short links
"""
import requests
import logging
import re
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

class URLResolver:
    def __init__(self):
        self.timeout = 10
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Referer': 'https://m.taobao.com/'
        }
        
        # CÃ¡c domain cáº§n resolve
        self.short_domains = [
            'e.tb.cn',
            'tb.cn', 
            's.tb.cn',
            'm.tb.cn',
            's.click.taobao.com',
            'uland.taobao.com',
            'qr.1688.com'  # ThÃªm há»— trá»£ 1688 QR links
        ]
        
        # CÃ¡c domain Ä‘Ã­ch há»£p lá»‡
        self.target_domains = [
            'detail.tmall.com',
            'item.taobao.com',
            'detail.1688.com'
        ]
        
        # Regex patterns Ä‘á»ƒ extract URL tá»« text
        # Cáº£i thiá»‡n Ä‘á»ƒ xá»­ lÃ½ URL cÃ³ kÃ½ tá»± thá»«a á»Ÿ cuá»‘i
        self.url_extraction_patterns = [
            # Pattern chÃ­nh: URL vá»›i domain vÃ  path, dá»«ng á»Ÿ kÃ½ tá»± khÃ´ng há»£p lá»‡
            r'https?://[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(?:/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*)?',
            # Pattern cho short links (qr.1688.com, e.tb.cn, etc.)
            r'https?://(?:qr\.1688\.com|e\.tb\.cn|tb\.cn|s\.tb\.cn|m\.tb\.cn|s\.click\.taobao\.com|uland\.taobao\.com)/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*',
            # Pattern cho full product URLs
            r'https?://(?:detail\.tmall\.com|item\.taobao\.com|detail\.1688\.com)/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*',
            # Fallback pattern cho cÃ¡c URL khÃ¡c
            r'https?://[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/[^\s]*',
        ]
        
        # Compiled patterns Ä‘á»ƒ tÄƒng performance
        self.compiled_url_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.url_extraction_patterns]
    
    def is_short_url(self, url: str) -> bool:
        """Kiá»ƒm tra cÃ³ pháº£i short URL khÃ´ng"""
        try:
            parsed = urlparse(url)
            return any(domain in parsed.netloc.lower() for domain in self.short_domains)
        except:
            return False
    
    def is_valid_target_url(self, url: str) -> bool:
        """Kiá»ƒm tra URL Ä‘Ã­ch cÃ³ há»£p lá»‡ khÃ´ng"""
        try:
            parsed = urlparse(url)
            return any(domain in parsed.netloc.lower() for domain in self.target_domains)
        except:
            return False
    
    def extract_urls_from_text(self, text: str) -> List[str]:
        """TrÃ­ch xuáº¥t táº¥t cáº£ URL tá»« text cÃ³ chá»¯ trÆ°á»›c"""
        urls = []
        
        for pattern in self.compiled_url_patterns:
            matches = pattern.findall(text)
            urls.extend(matches)
        
        # Loáº¡i bá» duplicate vÃ  clean up
        unique_urls = list(set(urls))
        cleaned_urls = [self._clean_url(url) for url in unique_urls]
        
        return [url for url in cleaned_urls if url]
    
    def _clean_url(self, url: str) -> str:
        """Clean up URL (loáº¡i bá» kÃ½ tá»± thá»«a á»Ÿ cuá»‘i)"""
        # Loáº¡i bá» kÃ½ tá»± khÃ´ng há»£p lá»‡ á»Ÿ cuá»‘i URL
        url = url.rstrip('.,;!?ï¼‰ã€‘ã€ ')
        
        # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng pháº£i URL character á»Ÿ cuá»‘i
        import re
        url = re.sub(r'[^a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]+$', '', url)
        
        # Äáº£m báº£o URL káº¿t thÃºc há»£p lá»‡
        if url.endswith('/'):
            url = url[:-1]
            
        return url
    
    def extract_best_url_from_text(self, text: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t URL tá»‘t nháº¥t tá»« text (Æ°u tiÃªn URL cÃ³ váº» lÃ  sáº£n pháº©m)"""
        urls = self.extract_urls_from_text(text)
        
        if not urls:
            return None
        
        # Æ¯u tiÃªn URL cÃ³ chá»©a tá»« khÃ³a sáº£n pháº©m
        product_keywords = ['taobao', 'tmall', '1688', 'item', 'detail', 'offer']
        
        for url in urls:
            if any(keyword in url.lower() for keyword in product_keywords):
                return url
        
        # Náº¿u khÃ´ng cÃ³ URL nÃ o chá»©a tá»« khÃ³a, tráº£ vá» URL Ä‘áº§u tiÃªn
        return urls[0]
    
    def get_final_url(self, short_url: str) -> Dict[str, Any]:
        """
        Resolve short URL thÃ nh final URL
        Há»— trá»£ cáº£ URL thuáº§n tÃºy vÃ  text cÃ³ chá»¯ trÆ°á»›c URL
        
        Args:
            short_url: URL cáº§n resolve hoáº·c text chá»©a URL
            
        Returns:
            Dict chá»©a thÃ´ng tin resolve result
        """
        try:
            logger.info(f"ğŸ” Resolving URL: {short_url}")
            
            # Kiá»ƒm tra xem input cÃ³ pháº£i lÃ  text chá»©a URL khÃ´ng
            extracted_url = None
            if not short_url.startswith(('http://', 'https://')):
                # CÃ³ thá»ƒ lÃ  text chá»©a URL, thá»­ extract
                extracted_url = self.extract_best_url_from_text(short_url)
                if extracted_url:
                    logger.info(f"ğŸ“ Extracted URL from text: {extracted_url}")
                    short_url = extracted_url
                else:
                    return {
                        'success': False,
                        'original_url': short_url,
                        'final_url': None,
                        'error': 'KhÃ´ng tÃ¬m tháº¥y URL há»£p lá»‡ trong text',
                        'method': 'no_url_found'
                    }
            
            # Náº¿u Ä‘Ã£ lÃ  URL há»£p lá»‡, return luÃ´n
            if self.is_valid_target_url(short_url):
                return {
                    'success': True,
                    'original_url': short_url,
                    'final_url': short_url,
                    'redirect_count': 0,
                    'method': 'no_redirect_needed',
                    'extracted_from_text': extracted_url is not None
                }
            
            # Náº¿u khÃ´ng pháº£i short URL, nhÆ°ng cÅ©ng khÃ´ng pháº£i target URL
            if not self.is_short_url(short_url):
                return {
                    'success': False,
                    'original_url': short_url,
                    'final_url': None,
                    'error': 'URL khÃ´ng Ä‘Æ°á»£c há»— trá»£',
                    'method': 'unsupported_domain',
                    'extracted_from_text': extracted_url is not None
                }
            
            # Resolve short URL vá»›i multiple strategies
            final_url, redirect_count = self._resolve_with_strategies(short_url)
            
            logger.info(f"âœ… Resolved: {short_url} â†’ {final_url} ({redirect_count} redirects)")
            
            # Kiá»ƒm tra final URL cÃ³ há»£p lá»‡ khÃ´ng
            if not self.is_valid_target_url(final_url):
                # Náº¿u khÃ´ng cÃ³ redirect, cÃ³ thá»ƒ link Ä‘Ã£ háº¿t háº¡n
                if redirect_count == 0:
                    error_msg = 'Link rÃºt gá»n cÃ³ thá»ƒ Ä‘Ã£ háº¿t háº¡n hoáº·c khÃ´ng hoáº¡t Ä‘á»™ng. Vui lÃ²ng thá»­ link Ä‘áº§y Ä‘á»§ tá»« trang sáº£n pháº©m.'
                else:
                    error_msg = f'Link redirect Ä‘áº¿n trang khÃ´ng Ä‘Æ°á»£c há»— trá»£: {final_url}'
                
                return {
                    'success': False,
                    'original_url': short_url,
                    'final_url': final_url,
                    'redirect_count': redirect_count,
                    'error': error_msg,
                    'method': 'invalid_final_url'
                }
            
            return {
                'success': True,
                'original_url': short_url,
                'final_url': final_url,
                'redirect_count': redirect_count,
                'method': 'redirect_resolved',
                'extracted_from_text': extracted_url is not None
            }
            
        except requests.Timeout:
            logger.error(f"âŒ Timeout khi resolve URL: {short_url}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': 'Timeout khi resolve URL',
                'method': 'timeout'
            }
            
        except requests.RequestException as e:
            logger.error(f"âŒ Lá»—i request khi resolve URL {short_url}: {e}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': f'Lá»—i request: {str(e)}',
                'method': 'request_error'
            }
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi resolve URL {short_url}: {e}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': f'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}',
                'method': 'unknown_error'
            }
    
    def _resolve_with_strategies(self, short_url: str) -> tuple:
        """
        Resolve URL: Thá»­ HTTP redirect trÆ°á»›c, náº¿u khÃ´ng cÃ³ thÃ¬ parse content
        Returns: (final_url, redirect_count)
        """
        try:
            logger.info(f"ğŸ” Resolving: {short_url}")
            
            # Strategy 1: Thá»­ HTTP redirect trÆ°á»›c
            response = requests.head(
                short_url, 
                headers=self.headers, 
                allow_redirects=True, 
                timeout=self.timeout
            )
            
            final_url = response.url
            redirect_count = len(response.history)
            
            # Náº¿u cÃ³ redirect, return ngay
            if redirect_count > 0 or self.is_valid_target_url(final_url):
                logger.info(f"âœ… HTTP redirect: {short_url} â†’ {final_url} ({redirect_count} redirects)")
                return final_url, redirect_count
            
            # Strategy 2: Náº¿u khÃ´ng cÃ³ HTTP redirect, parse content
            logger.info("No HTTP redirect, trying content parsing...")
            return self._parse_content_for_url(short_url)
            
        except requests.RequestException as e:
            logger.error(f"âŒ Request failed: {e}")
            return short_url, 0
    
    def _parse_content_for_url(self, short_url: str) -> tuple:
        """
        Parse HTML content Ä‘á»ƒ tÃ¬m URL Ä‘Ã­ch
        Returns: (final_url, redirect_count)
        """
        try:
            # GET request Ä‘á»ƒ láº¥y content
            response = requests.get(
                short_url, 
                headers=self.headers, 
                timeout=self.timeout
            )
            
            content = response.text
            logger.info(f"Got content: {len(content)} bytes")
            
            # TÃ¬m product URLs trong content
            product_patterns = [
                r'href=["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'href=["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'href=["\']([^"\']*detail\.1688\.com[^"\']*)["\']',
                r'url=["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'url=["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'url=["\']([^"\']*detail\.1688\.com[^"\']*)["\']',
                r'["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'["\']([^"\']*detail\.1688\.com[^"\']*)["\']'
            ]
            
            import re
            for pattern in product_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    # Filter valid URLs (cÃ³ id= vÃ  Ä‘á»§ dÃ i)
                    valid_matches = [m for m in matches if 'id=' in m and len(m) > 20]
                    if valid_matches:
                        final_url = valid_matches[0]
                        logger.info(f"âœ… Content parsing: {short_url} â†’ {final_url}")
                        return final_url, 1  # Simulate 1 redirect
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y, tÃ¬m product ID
            id_patterns = [
                r'itemId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'item_id["\']?\s*:\s*["\']?(\d+)["\']?',
                r'id["\']?\s*:\s*["\']?(\d{9,13})["\']?',
                r'productId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'offerId=(\d+)',  # ThÃªm pattern cho 1688 offerId
                r'offer\.id=(\d+)',  # ThÃªm pattern khÃ¡c cho 1688
                r'offer/(\d+)\.html'  # ThÃªm pattern tá»« URL path
            ]
            
            for pattern in id_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    product_id = matches[0]
                    
                    # XÃ¡c Ä‘á»‹nh domain dá»±a trÃªn short_url
                    if 'qr.1688.com' in short_url or '1688.com' in short_url:
                        # Construct 1688 URL
                        final_url = f"https://detail.1688.com/offer/{product_id}.html"
                        logger.info(f"âœ… 1688 ID extraction: {short_url} â†’ {final_url}")
                    else:
                        # Construct URL (default to Taobao)
                        final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                        logger.info(f"âœ… ID extraction: {short_url} â†’ {final_url}")
                    
                    return final_url, 1
            
            logger.warning("No product URL or ID found in content")
            return short_url, 0
            
        except Exception as e:
            logger.error(f"âŒ Content parsing failed: {e}")
            return short_url, 0
    
    

    def extract_product_id(self, url: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t product ID tá»« URL"""
        try:
            parsed = urlparse(url)
            
            # Thá»­ láº¥y tá»« query parameter 'id'
            from urllib.parse import parse_qs
            query_params = parse_qs(parsed.query)
            if 'id' in query_params:
                return query_params['id'][0]
            
            # Thá»­ tÃ¬m pattern sá»‘ trong URL
            import re
            match = re.search(r'(?:id=|/item/)(\d+)', url)
            if match:
                return match.group(1)
                
            return None
            
        except Exception as e:
            logger.error(f"Lá»—i khi extract product ID tá»« {url}: {e}")
            return None

# Táº¡o instance global Ä‘á»ƒ sá»­ dá»¥ng
url_resolver = URLResolver()

def resolve_product_url(url: str) -> Dict[str, Any]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ resolve URL sáº£n pháº©m
    Há»— trá»£ cáº£ URL thuáº§n tÃºy vÃ  text chá»©a URL
    
    Args:
        url: URL cáº§n resolve hoáº·c text chá»©a URL
        
    Returns:
        Dict chá»©a thÃ´ng tin resolve result
    """
    return url_resolver.get_final_url(url)

def extract_urls_from_text(text: str) -> List[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract URLs tá»« text
    
    Args:
        text: Text chá»©a URL
        
    Returns:
        List cÃ¡c URL Ä‘Æ°á»£c extract
    """
    return url_resolver.extract_urls_from_text(text)

def extract_best_url_from_text(text: str) -> Optional[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract URL tá»‘t nháº¥t tá»« text
    
    Args:
        text: Text chá»©a URL
        
    Returns:
        URL tá»‘t nháº¥t hoáº·c None
    """
    return url_resolver.extract_best_url_from_text(text)

def extract_product_id(url: str) -> Optional[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract product ID tá»« URL
    
    Args:
        url: URL chá»©a product ID
        
    Returns:
        Product ID string hoáº·c None
    """
    return url_resolver.extract_product_id(url)

# Test function
if __name__ == "__main__":
    # Test vá»›i cÃ¡c URL máº«u
    test_urls = [
        "https://e.tb.cn/h.SVYesMz1CWCGef8?tk=gGCY4DMdCiV",
        "https://detail.tmall.com/item.htm?id=777166626275",
        "https://item.taobao.com/item.htm?id=123456789",
        "https://google.com"  # Invalid URL
    ]
    
    # Test vá»›i text chá»©a URL
    test_texts = [
        "ã€æ·˜å®ã€‘å‡ä¸€èµ”å›› https://e.tb.cn/h.SU96zrxZvJOnr9h?tk=ORBN4yfCXn4 HU926 ã€Œçº¯æ¬²é£é»‘è‰²æŠ¹èƒ¸è¿è¡£è£™å¥³2025ç§‹æ³•å¼è½»ç†Ÿé£è½»å¥¢æ”¶è…°æ€§æ„Ÿå®´ä¼šç¤¼æœè£™ã€ç‚¹å‡»é“¾æ¥ç›´æ¥æ‰“å¼€ æˆ–è€… æ·˜å®æœç´¢ç›´æ¥æ‰“å¼€",
        "ã€æ·˜å®ã€‘å‡ä¸€èµ”å›› https://e.tb.cn/h.SfEU0GknEMtJgix?tk=pU7M4yfCR2L tG-#22>lD ã€Œé«˜çº§æ„Ÿé»‘è‰²é’ˆç»‡æŒ‚è„–èƒŒå¿ƒå¥³2025å¤æ³•å¼å¤å¤ååª›é£ä¿®èº«æ˜¾ç˜¦çŸ­æ¬¾ä¸Šè¡£ã€ç‚¹å‡»é“¾æ¥ç›´æ¥æ‰“å¼€ æˆ–è€… æ·˜å®æœç´¢ç›´æ¥æ‰“å¼€",
        "Check out this product: https://detail.1688.com/offer/953742824238.html - great quality!"
    ]
    
    print("=== Test with pure URLs ===")
    for test_url in test_urls:
        result = resolve_product_url(test_url)
        print(f"\nTest URL: {test_url}")
        print(f"Result: {result}")
        
        if result['success'] and result['final_url']:
            product_id = extract_product_id(result['final_url'])
            print(f"Product ID: {product_id}")
    
    print("\n=== Test with text containing URLs ===")
    for test_text in test_texts:
        print(f"\nTest Text: {test_text[:100]}...")
        
        # Test extract URLs
        urls = extract_urls_from_text(test_text)
        print(f"Extracted URLs: {urls}")
        
        # Test extract best URL
        best_url = extract_best_url_from_text(test_text)
        print(f"Best URL: {best_url}")
        
        # Test resolve
        result = resolve_product_url(test_text)
        print(f"Resolve Result: {result}")
        
        if result['success'] and result['final_url']:
            product_id = extract_product_id(result['final_url'])
            print(f"Product ID: {product_id}")
