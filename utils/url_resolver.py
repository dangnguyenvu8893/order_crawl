"""
URL Resolver Utility
Xá»­ lÃ½ viá»‡c resolve URL redirect Ä‘á»ƒ láº¥y URL cuá»‘i cÃ¹ng tá»« short links
"""
import requests
import logging
import re
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

class URLResolver:
    def __init__(self):
        self.timeout = 30  # TÄƒng timeout lÃªn 30 giÃ¢y
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Referer': 'https://m.taobao.com/'
        }
        
        # CÃ¡c domain cáº§n resolve (comprehensive list)
        self.short_domains = [
            # Taobao short links
            'e.tb.cn',
            'tb.cn', 
            's.tb.cn',
            'm.tb.cn',
            's.click.taobao.com',
            'uland.taobao.com',
            
            # Taobao mobile domains
            'm.taobao.com',
            'h5.m.taobao.com',
            
            # Tmall mobile domains
            'm.tmall.com',
            'h5.tmall.com',
            
            # 1688 domains
            'qr.1688.com',
            'm.1688.com',
            'h5.1688.com'
        ]
        
        # CÃ¡c domain Ä‘Ã­ch há»£p lá»‡ (comprehensive list)
        self.target_domains = [
            # Taobao desktop
            'item.taobao.com',
            
            # Tmall desktop
            'detail.tmall.com',
            
            # 1688 desktop
            'detail.1688.com',
            
            # Mobile domains (also valid targets)
            'm.taobao.com',
            'h5.m.taobao.com',
            'm.tmall.com',
            'h5.tmall.com',
            'm.1688.com',
            'h5.1688.com'
        ]
        
        # Regex patterns Ä‘á»ƒ extract URL tá»« text (comprehensive patterns)
        self.url_extraction_patterns = [
            # Pattern cho short links (Æ°u tiÃªn cao nháº¥t)
            r'https?://(?:qr\.1688\.com|e\.tb\.cn|tb\.cn|s\.tb\.cn|m\.tb\.cn|s\.click\.taobao\.com|uland\.taobao\.com)/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*',
            
            # Pattern cho mobile domains
            r'https?://(?:m\.taobao\.com|h5\.m\.taobao\.com|m\.tmall\.com|h5\.tmall\.com|m\.1688\.com|h5\.1688\.com)/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*',
            
            # Pattern cho desktop product URLs
            r'https?://(?:detail\.tmall\.com|item\.taobao\.com|detail\.1688\.com)/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*',
            
            # Pattern chÃ­nh: URL vá»›i domain vÃ  path, dá»«ng á»Ÿ kÃ½ tá»± khÃ´ng há»£p lá»‡
            r'https?://[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(?:/[a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]*)?',
            
            # Fallback pattern cho cÃ¡c URL khÃ¡c
            r'https?://[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/[^\s]*',
        ]
        
        # Compiled patterns Ä‘á»ƒ tÄƒng performance
        self.compiled_url_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.url_extraction_patterns]
    
    def is_short_url(self, url: str) -> bool:
        """Kiá»ƒm tra cÃ³ pháº£i short URL khÃ´ng"""
        try:
            parsed = urlparse(url)
            return any(domain in parsed.netloc.lower() for domain in self.short_domains)
        except:
            return False
    
    def is_valid_target_url(self, url: str) -> bool:
        """Kiá»ƒm tra URL Ä‘Ã­ch cÃ³ há»£p lá»‡ khÃ´ng"""
        try:
            parsed = urlparse(url)
            return any(domain in parsed.netloc.lower() for domain in self.target_domains)
        except:
            return False
    
    def extract_urls_from_text(self, text: str) -> List[str]:
        """TrÃ­ch xuáº¥t táº¥t cáº£ URL tá»« text cÃ³ chá»¯ trÆ°á»›c"""
        urls = []
        
        for pattern in self.compiled_url_patterns:
            matches = pattern.findall(text)
            urls.extend(matches)
        
        # Loáº¡i bá» duplicate vÃ  clean up
        unique_urls = list(set(urls))
        cleaned_urls = [self._clean_url(url) for url in unique_urls]
        
        return [url for url in cleaned_urls if url]
    
    def _clean_url(self, url: str) -> str:
        """Clean up URL (loáº¡i bá» kÃ½ tá»± thá»«a á»Ÿ cuá»‘i)"""
        # Loáº¡i bá» kÃ½ tá»± khÃ´ng há»£p lá»‡ á»Ÿ cuá»‘i URL
        url = url.rstrip('.,;!?ï¼‰ã€‘ã€ ')
        
        # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng pháº£i URL character á»Ÿ cuá»‘i
        import re
        url = re.sub(r'[^a-zA-Z0-9._~:/?#\[\]@!$&\'()*+,;=-]+$', '', url)
        
        # Äáº£m báº£o URL káº¿t thÃºc há»£p lá»‡
        if url.endswith('/'):
            url = url[:-1]
            
        return url
    
    def extract_best_url_from_text(self, text: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t URL tá»‘t nháº¥t tá»« text (Æ°u tiÃªn URL cÃ³ váº» lÃ  sáº£n pháº©m)"""
        urls = self.extract_urls_from_text(text)
        
        if not urls:
            return None
        
        # Æ¯u tiÃªn URL cÃ³ chá»©a tá»« khÃ³a sáº£n pháº©m
        product_keywords = ['taobao', 'tmall', '1688', 'item', 'detail', 'offer']
        
        for url in urls:
            if any(keyword in url.lower() for keyword in product_keywords):
                return url
        
        # Náº¿u khÃ´ng cÃ³ URL nÃ o chá»©a tá»« khÃ³a, tráº£ vá» URL Ä‘áº§u tiÃªn
        return urls[0]
    
    def get_final_url(self, short_url: str) -> Dict[str, Any]:
        """
        Resolve short URL thÃ nh final URL
        Há»— trá»£ cáº£ URL thuáº§n tÃºy vÃ  text cÃ³ chá»¯ trÆ°á»›c URL
        
        Args:
            short_url: URL cáº§n resolve hoáº·c text chá»©a URL
            
        Returns:
            Dict chá»©a thÃ´ng tin resolve result
        """
        try:
            logger.info(f"ğŸ” Resolving URL: {short_url}")
            
            # Kiá»ƒm tra xem input cÃ³ pháº£i lÃ  text chá»©a URL khÃ´ng
            extracted_url = None
            if not short_url.startswith(('http://', 'https://')):
                # CÃ³ thá»ƒ lÃ  text chá»©a URL, thá»­ extract
                extracted_url = self.extract_best_url_from_text(short_url)
                if extracted_url:
                    logger.info(f"ğŸ“ Extracted URL from text: {extracted_url}")
                    short_url = extracted_url
                else:
                    return {
                        'success': False,
                        'original_url': short_url,
                        'final_url': None,
                        'error': 'KhÃ´ng tÃ¬m tháº¥y URL há»£p lá»‡ trong text',
                        'method': 'no_url_found'
                    }
            
            # Náº¿u Ä‘Ã£ lÃ  URL há»£p lá»‡, return luÃ´n
            if self.is_valid_target_url(short_url):
                return {
                    'success': True,
                    'original_url': short_url,
                    'final_url': short_url,
                    'redirect_count': 0,
                    'method': 'no_redirect_needed',
                    'extracted_from_text': extracted_url is not None
                }
            
            # Náº¿u khÃ´ng pháº£i short URL, nhÆ°ng cÅ©ng khÃ´ng pháº£i target URL
            if not self.is_short_url(short_url):
                return {
                    'success': False,
                    'original_url': short_url,
                    'final_url': None,
                    'error': 'URL khÃ´ng Ä‘Æ°á»£c há»— trá»£',
                    'method': 'unsupported_domain',
                    'extracted_from_text': extracted_url is not None
                }
            
            # Resolve short URL vá»›i multiple strategies
            final_url, redirect_count = self._resolve_with_strategies(short_url)
            
            logger.info(f"âœ… Resolved: {short_url} â†’ {final_url} ({redirect_count} redirects)")
            
            # Kiá»ƒm tra náº¿u final_url lÃ  deep link, convert thÃ nh web URL trÆ°á»›c
            if final_url.startswith(('wireless1688://', 'taobao://', 'tmall://')):
                logger.info(f"ğŸ”„ Detected deep link, attempting conversion: {final_url}")
                # Extract content sau protocol
                deep_link_content = final_url.split('://', 1)[1] if '://' in final_url else final_url
                converted_url = self._convert_deep_link_to_web_url(deep_link_content, short_url)
                
                if converted_url and self.is_valid_target_url(converted_url):
                    logger.info(f"âœ… Successfully converted deep link: {final_url} â†’ {converted_url}")
                    return {
                        'success': True,
                        'original_url': short_url,
                        'final_url': converted_url,
                        'redirect_count': redirect_count + 1,
                        'method': 'deep_link_converted',
                        'extracted_from_text': extracted_url is not None
                    }
                else:
                    logger.warning(f"âŒ Deep link conversion failed or invalid result: {converted_url}")
            
            # Kiá»ƒm tra náº¿u final_url lÃ  mobile URL, convert thÃ nh desktop URL
            if self._is_mobile_url(final_url):
                logger.info(f"ğŸ”„ Detected mobile URL, attempting desktop conversion: {final_url}")
                desktop_url = self._convert_mobile_to_desktop_url(final_url)
                
                if desktop_url and self.is_valid_target_url(desktop_url):
                    logger.info(f"âœ… Successfully converted mobile to desktop: {final_url} â†’ {desktop_url}")
                    return {
                        'success': True,
                        'original_url': short_url,
                        'final_url': desktop_url,
                        'redirect_count': redirect_count + 1,
                        'method': 'mobile_to_desktop_converted',
                        'extracted_from_text': extracted_url is not None
                    }
                else:
                    logger.warning(f"âŒ Mobile to desktop conversion failed: {desktop_url}")
            
            # Kiá»ƒm tra final URL cÃ³ há»£p lá»‡ khÃ´ng
            if not self.is_valid_target_url(final_url):
                # Náº¿u khÃ´ng cÃ³ redirect, cÃ³ thá»ƒ link Ä‘Ã£ háº¿t háº¡n
                if redirect_count == 0:
                    error_msg = 'Link rÃºt gá»n cÃ³ thá»ƒ Ä‘Ã£ háº¿t háº¡n hoáº·c khÃ´ng hoáº¡t Ä‘á»™ng. Vui lÃ²ng thá»­ link Ä‘áº§y Ä‘á»§ tá»« trang sáº£n pháº©m.'
                else:
                    error_msg = f'Link redirect Ä‘áº¿n trang khÃ´ng Ä‘Æ°á»£c há»— trá»£: {final_url}'
                
                return {
                    'success': False,
                    'original_url': short_url,
                    'final_url': final_url,
                    'redirect_count': redirect_count,
                    'error': error_msg,
                    'method': 'invalid_final_url'
                }
            
            return {
                'success': True,
                'original_url': short_url,
                'final_url': final_url,
                'redirect_count': redirect_count,
                'method': 'redirect_resolved',
                'extracted_from_text': extracted_url is not None
            }
            
        except requests.Timeout:
            logger.error(f"âŒ Timeout khi resolve URL: {short_url}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': 'Timeout khi resolve URL',
                'method': 'timeout'
            }
            
        except requests.RequestException as e:
            logger.error(f"âŒ Lá»—i request khi resolve URL {short_url}: {e}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': f'Lá»—i request: {str(e)}',
                'method': 'request_error'
            }
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi resolve URL {short_url}: {e}")
            return {
                'success': False,
                'original_url': short_url,
                'final_url': None,
                'error': f'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}',
                'method': 'unknown_error'
            }
    
    def _resolve_with_strategies(self, short_url: str) -> tuple:
        """
        Resolve URL: Thá»­ HTTP redirect trÆ°á»›c, náº¿u khÃ´ng cÃ³ thÃ¬ parse content
        Returns: (final_url, redirect_count)
        """
        try:
            logger.info(f"ğŸ” Resolving: {short_url}")
            
            # Strategy 1: Thá»­ HTTP redirect trÆ°á»›c (HEAD request)
            try:
                response = requests.head(
                    short_url, 
                    headers=self.headers, 
                    allow_redirects=True, 
                    timeout=self.timeout
                )
            except requests.RequestException:
                # Náº¿u HEAD request tháº¥t báº¡i, thá»­ GET request
                logger.info("HEAD request failed, trying GET request...")
                response = requests.get(
                    short_url, 
                    headers=self.headers, 
                    allow_redirects=True, 
                    timeout=self.timeout
                )
            
            final_url = response.url
            redirect_count = len(response.history)
            
            # Náº¿u cÃ³ redirect, return ngay
            if redirect_count > 0 or self.is_valid_target_url(final_url):
                logger.info(f"âœ… HTTP redirect: {short_url} â†’ {final_url} ({redirect_count} redirects)")
                return final_url, redirect_count
            
            # Strategy 2: Thá»­ parse URL trá»±c tiáº¿p tá»« short URL
            logger.info("No HTTP redirect, trying direct URL parsing...")
            direct_result = self._parse_short_url_directly(short_url)
            if direct_result[1] > 0:  # Náº¿u cÃ³ káº¿t quáº£
                return direct_result
            
            # Strategy 3: Náº¿u khÃ´ng cÃ³ káº¿t quáº£, parse content
            logger.info("No direct parsing result, trying content parsing...")
            content_result = self._parse_content_for_url(short_url)
            if content_result[1] > 0:  # Náº¿u cÃ³ káº¿t quáº£
                return content_result
            
            # Strategy 4: Thá»­ vá»›i User-Agent khÃ¡c (desktop)
            logger.info("Content parsing failed, trying with desktop User-Agent...")
            return self._parse_with_desktop_ua(short_url)
            
        except requests.RequestException as e:
            logger.error(f"âŒ Request failed: {e}")
            return short_url, 0
    
    def _parse_short_url_directly(self, short_url: str) -> tuple:
        """
        Parse short URL trá»±c tiáº¿p Ä‘á»ƒ tÃ¬m product ID
        Returns: (final_url, redirect_count)
        """
        try:
            import re
            from urllib.parse import urlparse, parse_qs
            
            # Parse URL Ä‘á»ƒ láº¥y path vÃ  query parameters
            parsed = urlparse(short_url)
            path = parsed.path
            query_params = parse_qs(parsed.query)
            
            # TÃ¬m product ID trong path hoáº·c query parameters
            product_id = None
            
            # Thá»­ láº¥y tá»« query parameters
            for param_name in ['id', 'itemId', 'item_id', 'productId']:
                if param_name in query_params:
                    product_id = query_params[param_name][0]
                    break
            
            # Thá»­ tÃ¬m ID trong path
            if not product_id:
                id_match = re.search(r'/(\d{9,13})', path)
                if id_match:
                    product_id = id_match.group(1)
            
            # Thá»­ tÃ¬m ID trong toÃ n bá»™ URL
            if not product_id:
                id_match = re.search(r'(\d{9,13})', short_url)
                if id_match:
                    product_id = id_match.group(1)
            
            if product_id:
                # XÃ¡c Ä‘á»‹nh domain dá»±a trÃªn short_url (comprehensive logic)
                if 'qr.1688.com' in short_url or '1688.com' in short_url:
                    final_url = f"https://detail.1688.com/offer/{product_id}.html"
                elif 'm.tb.cn' in short_url or 'm.taobao.com' in short_url or 'h5.m.taobao.com' in short_url:
                    final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                elif 'm.tmall.com' in short_url or 'h5.tmall.com' in short_url or 'tmall' in short_url.lower():
                    final_url = f"https://detail.tmall.com/item.htm?id={product_id}"
                elif 'm.1688.com' in short_url or 'h5.1688.com' in short_url:
                    final_url = f"https://detail.1688.com/offer/{product_id}.html"
                else:
                    # Default to Taobao for unknown domains
                    final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                
                logger.info(f"âœ… Direct parsing: {short_url} â†’ {final_url}")
                return final_url, 1
            
            return short_url, 0
            
        except Exception as e:
            logger.error(f"âŒ Direct parsing failed: {e}")
            return short_url, 0
    
    def _parse_with_desktop_ua(self, short_url: str) -> tuple:
        """
        Parse URL vá»›i desktop User-Agent
        Returns: (final_url, redirect_count)
        """
        try:
            # Desktop User-Agent
            desktop_headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'max-age=0',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Referer': 'https://www.taobao.com/'
            }
            
            # Thá»­ GET request vá»›i desktop UA
            response = requests.get(
                short_url, 
                headers=desktop_headers, 
                allow_redirects=True,
                timeout=self.timeout
            )
            
            final_url = response.url
            redirect_count = len(response.history)
            
            # Náº¿u cÃ³ redirect vÃ  URL há»£p lá»‡
            if redirect_count > 0 and self.is_valid_target_url(final_url):
                logger.info(f"âœ… Desktop UA redirect: {short_url} â†’ {final_url} ({redirect_count} redirects)")
                return final_url, redirect_count
            
            # Náº¿u khÃ´ng cÃ³ redirect, thá»­ parse content
            content = response.text
            logger.info(f"Desktop UA got content: {len(content)} bytes")
            
            # TÃ¬m product ID trong content
            import re
            id_patterns = [
                r'itemId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'item_id["\']?\s*:\s*["\']?(\d+)["\']?',
                r'id["\']?\s*:\s*["\']?(\d{9,13})["\']?',
                r'productId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'[?&]id=(\d+)',
                r'[?&]itemId=(\d+)',
                r'[?&]item_id=(\d+)',
                r'[?&]productId=(\d+)'
            ]
            
            for pattern in id_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    product_id = matches[0]
                    
                    # XÃ¡c Ä‘á»‹nh domain dá»±a trÃªn short_url
                    if 'm.tb.cn' in short_url or 'm.taobao.com' in short_url or 'h5.m.taobao.com' in short_url:
                        final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                        logger.info(f"âœ… Desktop UA ID extraction: {short_url} â†’ {final_url}")
                        return final_url, 1
                    elif 'm.tmall.com' in short_url or 'h5.tmall.com' in short_url or 'tmall' in short_url.lower():
                        final_url = f"https://detail.tmall.com/item.htm?id={product_id}"
                        logger.info(f"âœ… Desktop UA Tmall ID extraction: {short_url} â†’ {final_url}")
                        return final_url, 1
                    elif 'qr.1688.com' in short_url or '1688.com' in short_url:
                        final_url = f"https://detail.1688.com/offer/{product_id}.html"
                        logger.info(f"âœ… Desktop UA 1688 ID extraction: {short_url} â†’ {final_url}")
                        return final_url, 1
            
            logger.warning("Desktop UA: No product ID found in content")
            return short_url, 0
            
        except Exception as e:
            logger.error(f"âŒ Desktop UA parsing failed: {e}")
            return short_url, 0
    
    def _parse_content_for_url(self, short_url: str) -> tuple:
        """
        Parse HTML content Ä‘á»ƒ tÃ¬m URL Ä‘Ã­ch
        Returns: (final_url, redirect_count)
        """
        try:
            # GET request Ä‘á»ƒ láº¥y content vá»›i retry logic
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = requests.get(
                        short_url, 
                        headers=self.headers, 
                        timeout=self.timeout
                    )
                    break
                except requests.Timeout:
                    if attempt < max_retries - 1:
                        logger.warning(f"Timeout attempt {attempt + 1}, retrying...")
                        continue
                    else:
                        logger.error(f"All {max_retries} attempts timed out")
                        return short_url, 0
                except requests.RequestException as e:
                    logger.error(f"Request failed: {e}")
                    return short_url, 0
            
            content = response.text
            logger.info(f"Got content: {len(content)} bytes")
            
            # TÃ¬m product URLs trong content (comprehensive patterns)
            product_patterns = [
                # Desktop URLs
                r'href=["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'href=["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'href=["\']([^"\']*detail\.1688\.com[^"\']*)["\']',
                r'url=["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'url=["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'url=["\']([^"\']*detail\.1688\.com[^"\']*)["\']',
                r'["\']([^"\']*detail\.tmall\.com[^"\']*)["\']',
                r'["\']([^"\']*item\.taobao\.com[^"\']*)["\']',
                r'["\']([^"\']*detail\.1688\.com[^"\']*)["\']',
                
                # Mobile URLs
                r'href=["\']([^"\']*m\.taobao\.com[^"\']*)["\']',
                r'href=["\']([^"\']*h5\.m\.taobao\.com[^"\']*)["\']',
                r'href=["\']([^"\']*m\.tmall\.com[^"\']*)["\']',
                r'href=["\']([^"\']*h5\.tmall\.com[^"\']*)["\']',
                r'href=["\']([^"\']*m\.1688\.com[^"\']*)["\']',
                r'href=["\']([^"\']*h5\.1688\.com[^"\']*)["\']',
                
                r'url=["\']([^"\']*m\.taobao\.com[^"\']*)["\']',
                r'url=["\']([^"\']*h5\.m\.taobao\.com[^"\']*)["\']',
                r'url=["\']([^"\']*m\.tmall\.com[^"\']*)["\']',
                r'url=["\']([^"\']*h5\.tmall\.com[^"\']*)["\']',
                r'url=["\']([^"\']*m\.1688\.com[^"\']*)["\']',
                r'url=["\']([^"\']*h5\.1688\.com[^"\']*)["\']',
                
                r'["\']([^"\']*m\.taobao\.com[^"\']*)["\']',
                r'["\']([^"\']*h5\.m\.taobao\.com[^"\']*)["\']',
                r'["\']([^"\']*m\.tmall\.com[^"\']*)["\']',
                r'["\']([^"\']*h5\.tmall\.com[^"\']*)["\']',
                r'["\']([^"\']*m\.1688\.com[^"\']*)["\']',
                r'["\']([^"\']*h5\.1688\.com[^"\']*)["\']',
                
                # Deep link patterns (wireless1688://, taobao://, tmall://)
                r'wireless1688://([^"\']*)["\']?',
                r'taobao://([^"\']*)["\']?',
                r'tmall://([^"\']*)["\']?'
            ]
            
            import re
            for pattern in product_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    # Xá»­ lÃ½ deep links trÆ°á»›c
                    if 'wireless1688://' in pattern or 'taobao://' in pattern or 'tmall://' in pattern:
                        for match in matches:
                            # Convert deep link thÃ nh web URL
                            web_url = self._convert_deep_link_to_web_url(match, short_url)
                            if web_url:
                                logger.info(f"âœ… Deep link conversion: {short_url} â†’ {web_url}")
                                return web_url, 1
                    
                    # Filter valid URLs (cÃ³ id= vÃ  Ä‘á»§ dÃ i)
                    valid_matches = [m for m in matches if 'id=' in m and len(m) > 20]
                    if valid_matches:
                        final_url = valid_matches[0]
                        logger.info(f"âœ… Content parsing: {short_url} â†’ {final_url}")
                        return final_url, 1  # Simulate 1 redirect
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y, tÃ¬m product ID
            id_patterns = [
                r'itemId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'item_id["\']?\s*:\s*["\']?(\d+)["\']?',
                r'id["\']?\s*:\s*["\']?(\d{9,13})["\']?',
                r'productId["\']?\s*:\s*["\']?(\d+)["\']?',
                r'offerId=(\d+)',  # ThÃªm pattern cho 1688 offerId
                r'offer\.id=(\d+)',  # ThÃªm pattern khÃ¡c cho 1688
                r'offer/(\d+)\.html',  # ThÃªm pattern tá»« URL path
                # ThÃªm patterns cho mobile taobao
                r'itemId["\']?\s*=\s*["\']?(\d+)["\']?',
                r'item_id["\']?\s*=\s*["\']?(\d+)["\']?',
                r'id["\']?\s*=\s*["\']?(\d{9,13})["\']?',
                r'productId["\']?\s*=\s*["\']?(\d+)["\']?',
                # ThÃªm patterns cho URL parameters
                r'[?&]id=(\d+)',
                r'[?&]itemId=(\d+)',
                r'[?&]item_id=(\d+)',
                r'[?&]productId=(\d+)'
            ]
            
            for pattern in id_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    product_id = matches[0]
                    
                    # XÃ¡c Ä‘á»‹nh domain dá»±a trÃªn short_url (comprehensive logic)
                    if 'qr.1688.com' in short_url or '1688.com' in short_url:
                        # Construct 1688 URL
                        final_url = f"https://detail.1688.com/offer/{product_id}.html"
                        logger.info(f"âœ… 1688 ID extraction: {short_url} â†’ {final_url}")
                    elif 'm.tb.cn' in short_url or 'm.taobao.com' in short_url or 'h5.m.taobao.com' in short_url:
                        # Construct mobile Taobao URL
                        final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                        logger.info(f"âœ… Mobile Taobao ID extraction: {short_url} â†’ {final_url}")
                    elif 'm.tmall.com' in short_url or 'h5.tmall.com' in short_url or 'tmall' in short_url.lower():
                        # Construct Tmall URL
                        final_url = f"https://detail.tmall.com/item.htm?id={product_id}"
                        logger.info(f"âœ… Tmall ID extraction: {short_url} â†’ {final_url}")
                    elif 'm.1688.com' in short_url or 'h5.1688.com' in short_url:
                        # Construct 1688 URL
                        final_url = f"https://detail.1688.com/offer/{product_id}.html"
                        logger.info(f"âœ… Mobile 1688 ID extraction: {short_url} â†’ {final_url}")
                    else:
                        # Construct URL (default to Taobao)
                        final_url = f"https://item.taobao.com/item.htm?id={product_id}"
                        logger.info(f"âœ… ID extraction: {short_url} â†’ {final_url}")
                    
                    return final_url, 1
            
            logger.warning("No product URL or ID found in content")
            return short_url, 0
            
        except Exception as e:
            logger.error(f"âŒ Content parsing failed: {e}")
            return short_url, 0
    
    def _convert_deep_link_to_web_url(self, deep_link_content: str, original_short_url: str) -> Optional[str]:
        """
        Convert deep link content thÃ nh web URL há»£p lá»‡
        Args:
            deep_link_content: Ná»™i dung cá»§a deep link (khÃ´ng bao gá»“m protocol)
            original_short_url: URL gá»‘c Ä‘á»ƒ xÃ¡c Ä‘á»‹nh platform
        Returns:
            Web URL há»£p lá»‡ hoáº·c None
        """
        try:
            import re
            from urllib.parse import parse_qs, urlparse
            
            logger.info(f"ğŸ”„ Converting deep link: {deep_link_content}")
            
            # TÃ¬m product ID trong deep link content
            product_id = None
            
            # Pattern cho 1688 offerId
            if 'offerId=' in deep_link_content:
                match = re.search(r'offerId=(\d+)', deep_link_content)
                if match:
                    product_id = match.group(1)
                    logger.info(f"Found 1688 offerId: {product_id}")
            
            # Pattern cho taobao/tmall itemId
            elif 'id=' in deep_link_content:
                match = re.search(r'id=(\d+)', deep_link_content)
                if match:
                    product_id = match.group(1)
                    logger.info(f"Found itemId: {product_id}")
            
            # Pattern cho path-based IDs
            elif '/offer/' in deep_link_content:
                match = re.search(r'/offer/(\d+)', deep_link_content)
                if match:
                    product_id = match.group(1)
                    logger.info(f"Found 1688 path offerId: {product_id}")
            
            elif '/item/' in deep_link_content:
                match = re.search(r'/item/(\d+)', deep_link_content)
                if match:
                    product_id = match.group(1)
                    logger.info(f"Found path itemId: {product_id}")
            
            # TÃ¬m ID báº±ng regex chung
            if not product_id:
                id_match = re.search(r'(\d{9,13})', deep_link_content)
                if id_match:
                    product_id = id_match.group(1)
                    logger.info(f"Found generic ID: {product_id}")
            
            if not product_id:
                logger.warning("No product ID found in deep link")
                return None
            
            # XÃ¡c Ä‘á»‹nh platform vÃ  táº¡o web URL
            if '1688' in deep_link_content or 'qr.1688.com' in original_short_url:
                web_url = f"https://detail.1688.com/offer/{product_id}.html"
                logger.info(f"âœ… Converted 1688 deep link: {web_url}")
                return web_url
            
            elif 'tmall' in deep_link_content or 'tmall' in original_short_url.lower():
                web_url = f"https://detail.tmall.com/item.htm?id={product_id}"
                logger.info(f"âœ… Converted Tmall deep link: {web_url}")
                return web_url
            
            elif 'taobao' in deep_link_content or 'taobao' in original_short_url.lower():
                web_url = f"https://item.taobao.com/item.htm?id={product_id}"
                logger.info(f"âœ… Converted Taobao deep link: {web_url}")
                return web_url
            
            else:
                # Default to 1688 náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c
                web_url = f"https://detail.1688.com/offer/{product_id}.html"
                logger.info(f"âœ… Default 1688 conversion: {web_url}")
                return web_url
                
        except Exception as e:
            logger.error(f"âŒ Deep link conversion failed: {e}")
            return None
    
    def _is_mobile_url(self, url: str) -> bool:
        """
        Kiá»ƒm tra xem URL cÃ³ pháº£i lÃ  mobile URL khÃ´ng
        Args:
            url: URL cáº§n kiá»ƒm tra
        Returns:
            True náº¿u lÃ  mobile URL
        """
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            netloc = parsed.netloc.lower()
            
            # Mobile domains
            mobile_domains = [
                'm.taobao.com',
                'h5.m.taobao.com', 
                'main.m.taobao.com',
                'm.tmall.com',
                'h5.tmall.com',
                'm.1688.com',
                'h5.1688.com'
            ]
            
            return any(domain in netloc for domain in mobile_domains)
            
        except Exception as e:
            logger.error(f"âŒ Error checking mobile URL: {e}")
            return False
    
    def _convert_mobile_to_desktop_url(self, mobile_url: str) -> Optional[str]:
        """
        Convert mobile URL thÃ nh desktop URL
        Args:
            mobile_url: Mobile URL cáº§n convert
        Returns:
            Desktop URL hoáº·c None
        """
        try:
            from urllib.parse import urlparse
            import re
            
            logger.info(f"ğŸ”„ Converting mobile URL to desktop: {mobile_url}")
            
            # Extract product ID tá»« mobile URL
            product_id = self.extract_product_id(mobile_url)
            
            if not product_id:
                logger.warning("No product ID found in mobile URL")
                return None
            
            # XÃ¡c Ä‘á»‹nh platform vÃ  táº¡o desktop URL
            parsed = urlparse(mobile_url)
            netloc = parsed.netloc.lower()
            
            if 'taobao.com' in netloc:
                desktop_url = f"https://item.taobao.com/item.htm?id={product_id}"
                logger.info(f"âœ… Converted Taobao mobile to desktop: {desktop_url}")
                return desktop_url
            
            elif 'tmall.com' in netloc:
                desktop_url = f"https://detail.tmall.com/item.htm?id={product_id}"
                logger.info(f"âœ… Converted Tmall mobile to desktop: {desktop_url}")
                return desktop_url
            
            elif '1688.com' in netloc:
                desktop_url = f"https://detail.1688.com/offer/{product_id}.html"
                logger.info(f"âœ… Converted 1688 mobile to desktop: {desktop_url}")
                return desktop_url
            
            else:
                logger.warning(f"Unknown platform for mobile URL: {netloc}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Mobile to desktop conversion failed: {e}")
            return None
    
    

    def extract_product_id(self, url: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t product ID tá»« URL"""
        try:
            parsed = urlparse(url)
            
            # Thá»­ láº¥y tá»« query parameter 'id'
            from urllib.parse import parse_qs
            query_params = parse_qs(parsed.query)
            if 'id' in query_params:
                return query_params['id'][0]
            
            # Thá»­ tÃ¬m pattern sá»‘ trong URL
            import re
            match = re.search(r'(?:id=|/item/)(\d+)', url)
            if match:
                return match.group(1)
                
            return None
            
        except Exception as e:
            logger.error(f"Lá»—i khi extract product ID tá»« {url}: {e}")
            return None

# Táº¡o instance global Ä‘á»ƒ sá»­ dá»¥ng
url_resolver = URLResolver()

def resolve_product_url(url: str) -> Dict[str, Any]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ resolve URL sáº£n pháº©m
    Há»— trá»£ cáº£ URL thuáº§n tÃºy vÃ  text chá»©a URL
    
    Args:
        url: URL cáº§n resolve hoáº·c text chá»©a URL
        
    Returns:
        Dict chá»©a thÃ´ng tin resolve result
    """
    return url_resolver.get_final_url(url)

def extract_urls_from_text(text: str) -> List[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract URLs tá»« text
    
    Args:
        text: Text chá»©a URL
        
    Returns:
        List cÃ¡c URL Ä‘Æ°á»£c extract
    """
    return url_resolver.extract_urls_from_text(text)

def extract_best_url_from_text(text: str) -> Optional[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract URL tá»‘t nháº¥t tá»« text
    
    Args:
        text: Text chá»©a URL
        
    Returns:
        URL tá»‘t nháº¥t hoáº·c None
    """
    return url_resolver.extract_best_url_from_text(text)

def extract_product_id(url: str) -> Optional[str]:
    """
    HÃ m tiá»‡n Ã­ch Ä‘á»ƒ extract product ID tá»« URL
    
    Args:
        url: URL chá»©a product ID
        
    Returns:
        Product ID string hoáº·c None
    """
    return url_resolver.extract_product_id(url)

# Test function
if __name__ == "__main__":
    # Test vá»›i cÃ¡c URL máº«u
    test_urls = [
        "https://e.tb.cn/h.SVYesMz1CWCGef8?tk=gGCY4DMdCiV",
        "https://detail.tmall.com/item.htm?id=777166626275",
        "https://item.taobao.com/item.htm?id=123456789",
        "https://google.com"  # Invalid URL
    ]
    
    # Test vá»›i text chá»©a URL
    test_texts = [
        "ã€æ·˜å®ã€‘å‡ä¸€èµ”å›› https://e.tb.cn/h.SU96zrxZvJOnr9h?tk=ORBN4yfCXn4 HU926 ã€Œçº¯æ¬²é£é»‘è‰²æŠ¹èƒ¸è¿è¡£è£™å¥³2025ç§‹æ³•å¼è½»ç†Ÿé£è½»å¥¢æ”¶è…°æ€§æ„Ÿå®´ä¼šç¤¼æœè£™ã€ç‚¹å‡»é“¾æ¥ç›´æ¥æ‰“å¼€ æˆ–è€… æ·˜å®æœç´¢ç›´æ¥æ‰“å¼€",
        "ã€æ·˜å®ã€‘å‡ä¸€èµ”å›› https://e.tb.cn/h.SfEU0GknEMtJgix?tk=pU7M4yfCR2L tG-#22>lD ã€Œé«˜çº§æ„Ÿé»‘è‰²é’ˆç»‡æŒ‚è„–èƒŒå¿ƒå¥³2025å¤æ³•å¼å¤å¤ååª›é£ä¿®èº«æ˜¾ç˜¦çŸ­æ¬¾ä¸Šè¡£ã€ç‚¹å‡»é“¾æ¥ç›´æ¥æ‰“å¼€ æˆ–è€… æ·˜å®æœç´¢ç›´æ¥æ‰“å¼€",
        "Check out this product: https://detail.1688.com/offer/953742824238.html - great quality!"
    ]
    
    print("=== Test with pure URLs ===")
    for test_url in test_urls:
        result = resolve_product_url(test_url)
        print(f"\nTest URL: {test_url}")
        print(f"Result: {result}")
        
        if result['success'] and result['final_url']:
            product_id = extract_product_id(result['final_url'])
            print(f"Product ID: {product_id}")
    
    print("\n=== Test with text containing URLs ===")
    for test_text in test_texts:
        print(f"\nTest Text: {test_text[:100]}...")
        
        # Test extract URLs
        urls = extract_urls_from_text(test_text)
        print(f"Extracted URLs: {urls}")
        
        # Test extract best URL
        best_url = extract_best_url_from_text(test_text)
        print(f"Best URL: {best_url}")
        
        # Test resolve
        result = resolve_product_url(test_text)
        print(f"Resolve Result: {result}")
        
        if result['success'] and result['final_url']:
            product_id = extract_product_id(result['final_url'])
            print(f"Product ID: {product_id}")
